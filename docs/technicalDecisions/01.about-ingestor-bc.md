# Decisions made in `Ingestor` Bounded Context (in no particular order)
### Why using `httpClient` instead of `Guzzle`?
Simplicity reasons: `Guzzle` is widely used for HTTP requests, but it adds an extra layer of complexity to our codebase. 
Our external provider only exposes `GET` endpoints, so no need to have (and maintain) an all-purpose library (like `Guzzle`) when a simpler and more lightweight option allows us to do the trick.

### How to check the fake XML data provider?
I created a dumb controller with hardcoded silly data. In order to simulate different moments of the day, there are 3 different routes:
- http://localhost:8000/external-provider/events/moment-1
- http://localhost:8000/external-provider/events/moment-2
- http://localhost:8000/external-provider/events/moment-3

The fake controller is located in `apps/SymfonyClient/src/Controller/ExternalProviderController.php`

### What if our external provider has thousands of events with hundreds of zones each? 
The CLI uses the `src/Ingestor/Infrastructure/XmlEventsStreamReader` class to reads from XML using streaming to avoid memory exhaustion.
It also processes in batches (default size is 50, but it could be increased if needed).

That combination of factors (streaming + batch processing) allows us to process any number of events with constant memory usage (around 5 MB).

When the batch arrives at the `src/Ingestor/Application/IngestEventsCommandHandler.php`, it sends its events (one by one) to a Redis instance to be processed asynchronously.
That means we can have dedicated workers to process the events in the background, and we can scale them up or down depending on the workload.

The messages in Redis are stored as JSON strings, so they are interoperable (and also, easy to read, debug and test).

### Why the `Zone.price` is converted as `int`?
In order to avoid floating point precision issues, I decided to store the price as an integer representing the amount in cents.
I would also have liked using the `Money` pattern in this particular VO, but the endpoint does not provide the currency.

### About rabbit queues...
We have N queues (N = number of domain events). The *exchange name* is `domain_events` and the *routing key* is the name of the event (e.g. `event_created`, `event_updated`, etc.).
When the project is built (`make build`), there is a process (located in `etc/scripts/wait-for-rabbitmq.sh`) that waits for RabbitMQ to be ready and then creates the queues and the exchange.

The idea behind having one queue per event is to have a clear separation of concerns and to be able to scale each queue independently. For example, if we have a lot of `event_created` events, we can scale up the workers that consume from that queue without affecting the other queues.

*Sure, the naming (wait-for-rabbitmq) is not the best one, but it does the job.*

### How to use this BC:
1. Run `make build` first to make sure the mysql migrations are executed, the Redis instance is running and the RabbitMQ queues are created and configured. 
2. Type `make shell` to access the PHP container's shell.
3. Run `bin/console app:activities:ingest` and wait until the events are enqueued in Redis.
4. Check the Redis instance at http://localhost:5540/ (Connection URL: `redis://default@redis_container:6379`) to see the enqueued messages.
5. Run `bin/console messenger:consume redis-async` to process the Redis messages: this action will fetch the messages from Redis, persist the aggregate roots in the database and store events in the `outbox_events` table.
6. Check the `outbox_events` table in mysql: you will see the domain events stored here (with the `published_at` field = NULL)
7. Run `bin/console outbox:relay` to move the domain events to the rabbitMQ instance. 
8. Check the rabbitMQ UI at http://localhost:15672/ (username: admin, password: admin) to see the published messages in the `domain_events` exchange.
9. You can also check the database (tables `events` and `event_zones`) to see the persisted data. Use your preferred MySQL client (host: localhost:3306, username: root, password: root, database: ingestor_db).
10. Run `bin/console messenger:consume rabbitmq-async` to see how the Catalog BC reacts to the Domain events and start updating its own projections.
